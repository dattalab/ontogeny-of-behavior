{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4494b89a-db19-4894-aa21-0a1cc851cdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from aging.organization.paths import FOLDERS\n",
    "from aging.size_norm.data import clean\n",
    "from aging.video import write_movie_av\n",
    "from scipy.ndimage import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca02da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_slice(pos, pad):\n",
    "    pos = int(pos) + pad\n",
    "    return slice(pos - 40, pos + 40)\n",
    "\n",
    "\n",
    "def is_ok_position(pos, pad, max_pos):\n",
    "    pos = int(pos) + pad\n",
    "    return ((pos - 40) > 0) and ((pos + 40) < max_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33de8c1-8d2e-4ab6-b421-fa66993a5ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = 12\n",
    "syllable_path = f\"/n/groups/datta/win/longtogeny/data/ontogeny/version_{version:02d}/all_data_pca/syllables.h5\"\n",
    "pca_path = f\"/n/groups/datta/win/longtogeny/data/ontogeny/version_{version:02d}/all_data_pca/pca_scores.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc558ccb-5ffd-4858-b099-9e3c2ca50edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62e4b4b8aef48629177d6c1fe7ea982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uuid_map = defaultdict(dict)\n",
    "bad_examples = []\n",
    "\n",
    "for folder in tqdm(FOLDERS):\n",
    "    for file in folder.glob('**/*results_00.h5'):\n",
    "        try:\n",
    "            with h5py.File(file, 'r') as h5f:\n",
    "                uuid = h5f['metadata/uuid'][()].decode()\n",
    "                uuid_map[folder][uuid] = file\n",
    "        except OSError:\n",
    "            bad_examples.append(file)\n",
    "uuid_map = dict(uuid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172f3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dur = 5  # frames\n",
    "max_dur = 60\n",
    "pad = 30  # frames\n",
    "n_examples = 40\n",
    "seed = 0\n",
    "frames_key = 'frames'  # or win_size_norm_frames_v4\n",
    "cm_keys = ['centroid_x_px', 'centroid_y_px', 'angle']\n",
    "\n",
    "radius = 2\n",
    "center = (80 // 2, ) * 2  # hard-coded for aging project\n",
    "height_thresh = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fcfca-f6d9-470a-83fb-264064190c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2f713b4ddc478287652d632908e0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing experiments:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921f47ff40434d1abafab52dd818bd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting syllables:   0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94e85c8b02a4d5eb3865e5b6b1635eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing movies:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98596932704a44c1af42c1e55a41eb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting syllables:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe16615da354d8eb51d8e9d67cbe4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing movies:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb313daf5974fce8f9ac449a9e9b9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting syllables:   0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bee4fdc522146ef8ad86c675bc01577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing movies:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dbc5a29ba546bfb0ceaac2b516fbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting syllables:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b2462149c146c68846e4a4517dd2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing movies:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7cd92b9fdd41d0b87dc4b08bd8ef94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting syllables:   0%|          | 0/968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104d96d70b8c4820b0a10352d07f9385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing movies:   0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6ef89a65784a92b7de6476c721cbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting syllables:   0%|          | 0/1401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e86c71190d4d4eb1ff899f105213e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing movies:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_crowd_movie_folder = Path(\n",
    "    f\"/n/groups/datta/win/longtogeny/data/ontogeny/version_{version:02d}/all_data_pca/crowd_movies\"\n",
    ")\n",
    "for FOLDER in tqdm(FOLDERS, desc=\"Processing experiments\"):\n",
    "    crowd_movie_folder = base_crowd_movie_folder / FOLDER.name\n",
    "    # open syllable and pca h5 file\n",
    "    uuid_dict = uuid_map[FOLDER]\n",
    "    with h5py.File(syllable_path, \"r\") as syll_h5, h5py.File(pca_path, \"r\") as pca_h5:\n",
    "        # construct df for syllables in this experiment:\n",
    "        df = []\n",
    "        for uuid, file in uuid_dict.items():\n",
    "            try:\n",
    "                df.append(\n",
    "                    pd.DataFrame(\n",
    "                        dict(\n",
    "                            syllables=syll_h5[uuid][()],\n",
    "                            uuid=uuid,\n",
    "                            file=str(file),\n",
    "                            frame_idx=pca_h5[\"scores_idx\"][uuid][()],\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    # concatenate dataframe, compute syllable durations\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    df[\"onsets\"] = df.groupby(\"uuid\", sort=False)[\"syllables\"].transform(\n",
    "        lambda v: v.diff() != 0\n",
    "    )\n",
    "    idx = np.where(df[\"onsets\"])[0]\n",
    "    df.loc[df[\"onsets\"], \"duration\"] = np.append(np.diff(idx), [len(df) - idx[-1]])\n",
    "    df[\"duration\"] = df[\"duration\"].ffill().astype(\"uint16\")\n",
    "    syllables = df[\"syllables\"].unique()\n",
    "    df = df.dropna(subset=[\"frame_idx\"])\n",
    "    df[\"frame_idx\"] = df[\"frame_idx\"].astype(\"uint32\")\n",
    "    usages_map = dict(\n",
    "        map(reversed, enumerate(df.query(\"onsets\")[\"syllables\"].value_counts().index))\n",
    "    )\n",
    "\n",
    "    crowd_matrix_dict = {}\n",
    "    total_examples = []\n",
    "\n",
    "    for syllable in syllables:\n",
    "        mask = (\n",
    "            (df[\"syllables\"] == syllable)\n",
    "            & df[\"duration\"].between(min_dur, max_dur)\n",
    "            & df[\"onsets\"]\n",
    "            & (df[\"frame_idx\"] > pad)\n",
    "        )\n",
    "        examples = df[mask].sample(n=min(n_examples, mask.sum()), random_state=seed)\n",
    "        examples = examples.sort_values(by=[\"file\", \"frame_idx\"])\n",
    "        if len(examples) == 0:\n",
    "            continue\n",
    "        total_examples.append(examples)\n",
    "        crowd_matrix_dict[syllable] = np.zeros(\n",
    "            (examples[\"duration\"].max() + pad * 2, 424, 512), dtype=\"uint8\"\n",
    "        )\n",
    "    total_examples = pd.concat(total_examples, ignore_index=True)\n",
    "\n",
    "    for file, _df in tqdm(\n",
    "        total_examples.groupby(\"file\", sort=False), desc=\"Extracting syllables\"\n",
    "    ):\n",
    "        with h5py.File(file, \"r\") as h5f:\n",
    "            extents = np.where(h5f[\"metadata/extraction/roi\"])\n",
    "            y_min = extents[0].min()\n",
    "            x_min = extents[1].min()\n",
    "            for idx, row in _df.sort_values(by=\"frame_idx\").iterrows():\n",
    "                agg_feats = {}\n",
    "                start = row.frame_idx - pad\n",
    "                end = row.frame_idx + row.duration + pad\n",
    "                agg_feats[\"frames\"] = np.array(\n",
    "                    [clean(f) for f in h5f[frames_key][start:end]]\n",
    "                )\n",
    "                for key in cm_keys:\n",
    "                    agg_feats[key] = h5f[\"scalars\"][key][start:end]\n",
    "                flips = h5f[\"metadata/extraction/flips\"][start:end]\n",
    "                # agg_feats[\"angle\"] -= np.pi * flips\n",
    "                agg_feats[\"angle\"] = np.rad2deg(agg_feats[\"angle\"])\n",
    "                rotated = np.array(\n",
    "                    [\n",
    "                        rotate(f, a, reshape=False)\n",
    "                        for f, a in zip(agg_feats[\"frames\"], agg_feats[\"angle\"])\n",
    "                    ],\n",
    "                    dtype=\"uint8\",\n",
    "                )\n",
    "                rotated[\n",
    "                    pad:-pad,\n",
    "                    center[0] - radius : center[0] + radius,\n",
    "                    center[1] - radius : center[1] + radius,\n",
    "                ] = 255\n",
    "                for i, (x, y, frame) in enumerate(\n",
    "                    zip(\n",
    "                        agg_feats[\"centroid_x_px\"],\n",
    "                        agg_feats[\"centroid_y_px\"],\n",
    "                        rotated,\n",
    "                    )\n",
    "                ):\n",
    "                    if np.isnan(x) or np.isnan(y):\n",
    "                        continue\n",
    "                    if not is_ok_position(y, y_min, 424) or not is_ok_position(\n",
    "                        x, x_min, 512\n",
    "                    ):\n",
    "                        continue\n",
    "                    ys, xs = make_slice(y, y_min), make_slice(x, x_min)\n",
    "                    crowd_matrix_dict[row.syllables][i, ys, xs] = frame + (\n",
    "                        (frame < height_thresh)\n",
    "                        * crowd_matrix_dict[row.syllables][i, ys, xs]\n",
    "                    )\n",
    "\n",
    "    for syllable, mov in tqdm(crowd_matrix_dict.items(), desc=\"Writing movies\"):\n",
    "        write_movie_av(\n",
    "            crowd_movie_folder\n",
    "            / f\"usage_order_{usages_map[syllable]:02d}-syllable_{syllable:02d}.mp4\",\n",
    "            np.clip(mov, 0, 95),\n",
    "            cmap=\"cubehelix\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dbfac-a58d-4614-8084-27bf7f50f9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ontogeny",
   "language": "python",
   "name": "aging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
