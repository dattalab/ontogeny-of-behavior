{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da727b1e-e418-443c-9fce-881bd4ba6863",
   "metadata": {},
   "source": [
    "# Take inferred syllables from ARHMM and assign mouse ID and experiment to each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa78d85-33c0-4298-a61e-1d32c52ff5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from datetime import datetime\n",
    "from toolz.curried import pluck\n",
    "from aging.organization.paths import FOLDERS\n",
    "from aging.behavior.scalars import compute_scalars\n",
    "from toolz import concat, compose, valmap, first, groupby, keyfilter, keymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa13adc3-bd5a-44ba-a52f-697bf7fc28a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cpus = int(os.environ.get('SLURM_CPUS_PER_TASK', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1dfefe-f6eb-4273-b92f-f197cbef66c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = 6\n",
    "data_folder = Path(f'/n/groups/datta/win/longtogeny/data/ontogeny/version_{version:02d}')\n",
    "syllable_path = data_folder / 'all_data_pca/syllables.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3228bb7-c854-4894-8d13-2aa0c76482eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aac5308c2d64591a410d9ad9c813a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uuid_map = {}\n",
    "for file in tqdm(concat(f.glob('**/results_00.h5') for f in FOLDERS)):\n",
    "    try:\n",
    "        with h5py.File(file, 'r') as h5f:\n",
    "            uuid = h5f['metadata/uuid'][()].decode()\n",
    "            uuid_map[uuid] = file\n",
    "    except OSError:\n",
    "        continue\n",
    "\n",
    "with h5py.File(syllable_path, 'r') as h5f:\n",
    "    h5f_uuids = list(h5f)\n",
    "    uuid_map = keyfilter(lambda u: u in h5f_uuids, uuid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a3e800-4315-4b0f-9cea-0c68419bf18a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ColorDataType', 'ColorResolution', 'DepthDataType', 'DepthResolution', 'IsLittleEndian', 'NidaqChannels', 'NidaqSamplingRate', 'SessionName', 'StartTime', 'SubjectName']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(first(uuid_map.values()), 'r') as h5f:\n",
    "    print(list(h5f['metadata/acquisition']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f702e8b-e36a-4cbb-b5f4-9bb180dd7c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_experiment(path: Path):\n",
    "    str_path = str(path)\n",
    "    if \"min\" in str_path and 'longtogeny' in str_path:\n",
    "        exp = f\"longtogeny_v2_{path.parents[2].name.lower()}\"\n",
    "    elif \"dlight\" in str_path:\n",
    "        return \"dlight\"\n",
    "    elif \"longtogeny\" in str(path):\n",
    "        sex = path.parents[3].name.lower()\n",
    "        if sex not in (\"males\", \"females\"):\n",
    "            sex = path.parents[2].name.lower()\n",
    "            if sex not in (\"males\", \"females\"):\n",
    "                raise ValueError(\"bleh\")\n",
    "        exp = f\"longtogeny_{sex}\"\n",
    "    elif \"ontogeny\" in str(path).lower() and \"community\" not in str(path):\n",
    "        exp = path.parents[3].name.lower()\n",
    "        if exp == \"raw_data\":\n",
    "            exp = path.parents[2].name.lower()\n",
    "    elif \"wheel\" in str(path).lower():\n",
    "        exp = \"wheel\"\n",
    "    else:\n",
    "        exp = path.parents[2].name\n",
    "        print(exp)\n",
    "    return exp\n",
    "\n",
    "\n",
    "def insert_nans(timestamps, data, fps=30):\n",
    "    df_timestamps = np.diff(np.insert(timestamps, 0, timestamps[0] - 1.0 / fps))\n",
    "    missing_frames = np.floor(df_timestamps / (1.0 / fps))\n",
    "\n",
    "    fill_idx = np.where(missing_frames > 1)[0]\n",
    "    data_idx = np.arange(len(timestamps)).astype('float64')\n",
    "\n",
    "    filled_data = deepcopy(data)\n",
    "    filled_timestamps = deepcopy(timestamps)\n",
    "\n",
    "    if filled_data.ndim == 1:\n",
    "        isvec = True\n",
    "        filled_data = filled_data[:, None]\n",
    "    else:\n",
    "        isvec = False\n",
    "    nframes, nfeatures = filled_data.shape\n",
    "\n",
    "    for idx in fill_idx[::-1]:\n",
    "        if idx < len(missing_frames):\n",
    "            ninserts = int(missing_frames[idx] - 1)\n",
    "            data_idx = np.insert(data_idx, idx, [np.nan] * ninserts)\n",
    "            insert_timestamps = timestamps[idx - 1] + \\\n",
    "                np.cumsum(np.ones(ninserts,) * 1.0 / fps)\n",
    "            filled_data = np.insert(filled_data, idx,\n",
    "                                    np.ones((ninserts, nfeatures)) * np.nan, axis=0)\n",
    "            filled_timestamps = np.insert(\n",
    "                filled_timestamps, idx, insert_timestamps)\n",
    "\n",
    "    if isvec:\n",
    "        filled_data = np.squeeze(filled_data)\n",
    "\n",
    "    return filled_data, data_idx, filled_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2016e060-8f4b-4686-a4b6-e126fe8a412a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group uuids by experiment\n",
    "exp_groups = groupby(lambda k: get_experiment(k[1]), uuid_map.items())\n",
    "exp_groups = valmap(compose(list, pluck(0)), exp_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d455593a-42ea-434a-ba68-cffb55999d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ontogeny_females',\n",
       " 'ontogeny_males',\n",
       " 'longtogeny_males',\n",
       " 'longtogeny_v2_females',\n",
       " 'longtogeny_v2_males',\n",
       " 'wheel',\n",
       " 'dlight']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(exp_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d993377c-a721-4f49-9a61-1da1c906a3bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ontogeny_females': 224,\n",
       " 'ontogeny_males': 216,\n",
       " 'longtogeny_males': 977,\n",
       " 'longtogeny_v2_females': 757,\n",
       " 'longtogeny_v2_males': 188,\n",
       " 'wheel': 826,\n",
       " 'dlight': 171}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valmap(len, exp_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50e71461-d95d-437e-bf5b-5a3d10bee129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_scalars(path: Path, recon_key, rescaled_key):\n",
    "    try:\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            session_name = f[\"metadata/acquisition/SessionName\"][()].decode()\n",
    "            subject_name = f[\"metadata/acquisition/SubjectName\"][()].decode()\n",
    "            keep_scalars = list(filter(lambda k: \"mm\" in k, f[\"scalars\"])) + [\n",
    "                \"angle\",\n",
    "                \"velocity_theta\",\n",
    "            ]\n",
    "\n",
    "            ts = f[\"timestamps\"][()] / 1000\n",
    "            scalars = dict((k, f[\"scalars\"][k][()]) for k in keep_scalars)\n",
    "            filled_scalars = valmap(lambda v: insert_nans(ts, v)[0], scalars)\n",
    "            filled_ts = insert_nans(ts, ts)[2]\n",
    "\n",
    "            frames = f[recon_key][()]\n",
    "            centroid = np.array(\n",
    "                [f[\"scalars/centroid_x_px\"][()], f[\"scalars/centroid_y_px\"][()]]\n",
    "            ).T\n",
    "            true_depth = f[\"metadata/extraction/true_depth\"][()]\n",
    "            recon_scalars = compute_scalars(frames, centroid, true_depth)\n",
    "            recon_scalars = valmap(lambda v: insert_nans(ts, v)[0], recon_scalars)\n",
    "            # also add rescaled scalars\n",
    "            frames = f[rescaled_key][()]\n",
    "            rescaled_scalars = compute_scalars(frames, is_recon=False)\n",
    "            rescaled_scalars = keymap(lambda k: f\"rescaled_{k}\", rescaled_scalars)\n",
    "            rescaled_scalars = valmap(lambda v: insert_nans(ts, v)[0], rescaled_scalars)\n",
    "        return dict(\n",
    "            true_depth=true_depth,\n",
    "            session_name=session_name,\n",
    "            subject_name=subject_name,\n",
    "            timestamps=filled_ts - filled_ts[0],\n",
    "            **filled_scalars,\n",
    "            **recon_scalars,\n",
    "            **rescaled_scalars,\n",
    "        )\n",
    "    except (OSError, KeyError) as e:\n",
    "        print(\"Error with\", str(path))\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b94c30-03c7-4ee9-ac6f-3ed2e79ca3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bbcc0358374fb9bef3ad8959218990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wg41/miniconda3/envs/aging/lib/python3.10/site-packages/numpy/lib/function_base.py:5394: RuntimeWarning: invalid value encountered in cast\n",
      "  values = array(values, copy=False, ndmin=arr.ndim, dtype=arr.dtype)\n",
      "/home/wg41/miniconda3/envs/aging/lib/python3.10/site-packages/numpy/lib/function_base.py:5394: RuntimeWarning: invalid value encountered in cast\n",
      "  values = array(values, copy=False, ndmin=arr.ndim, dtype=arr.dtype)\n",
      "/home/wg41/miniconda3/envs/aging/lib/python3.10/site-packages/numpy/lib/function_base.py:5394: RuntimeWarning: invalid value encountered in cast\n",
      "  values = array(values, copy=False, ndmin=arr.ndim, dtype=arr.dtype)\n",
      "/home/wg41/miniconda3/envs/aging/lib/python3.10/site-packages/numpy/lib/function_base.py:5394: RuntimeWarning: invalid value encountered in cast\n",
      "  values = array(values, copy=False, ndmin=arr.ndim, dtype=arr.dtype)\n"
     ]
    }
   ],
   "source": [
    "recon_frames_key = \"win_size_norm_frames_v4\"\n",
    "rescaled_frames_key = \"rescaled_frames\"\n",
    "df_version = 0\n",
    "failed_sessions = []\n",
    "with h5py.File(syllable_path, \"r\") as h5f:\n",
    "    for experiment, uuids in exp_groups.items():\n",
    "        # remove this line to do everything\n",
    "        df = []\n",
    "        for i, (uuid, path) in enumerate(map(lambda u: (u, uuid_map[u]), tqdm(uuids))):\n",
    "            extraction_data = extract_scalars(path, recon_frames_key, rescaled_frames_key)\n",
    "            if extraction_data is None:\n",
    "                extraction_data = dict(session_name='', subject_name='')\n",
    "            if \"longtogeny\" in experiment:\n",
    "                age = np.nan\n",
    "            elif \"ontogeny\" in experiment:\n",
    "                age = path.parents[2].name.split(\"_\")[0]\n",
    "            else:\n",
    "                age = np.nan\n",
    "            date = datetime.strptime(\n",
    "                path.parents[1].name.split(\"_\")[-1], \"%Y%m%d%H%M%S\"\n",
    "            )\n",
    "            try:\n",
    "                _df = pd.DataFrame(\n",
    "                    dict(\n",
    "                        experiment=experiment,\n",
    "                        file=str(path),\n",
    "                        syllables=h5f[uuid][()],\n",
    "                        date=date,\n",
    "                        uuid=uuid,\n",
    "                        age=age,\n",
    "                        **extraction_data,\n",
    "                    )\n",
    "                )\n",
    "                _df = _df.astype(\n",
    "                    dict(\n",
    "                        syllables=\"int16[pyarrow]\",\n",
    "                        file=\"string[pyarrow]\",\n",
    "                        experiment=\"string[pyarrow]\",\n",
    "                        uuid=\"string[pyarrow]\",\n",
    "                        session_name=\"string[pyarrow]\",\n",
    "                        subject_name=\"string[pyarrow]\",\n",
    "                        timestamps=\"float32[pyarrow]\",\n",
    "                        true_depth=\"float32[pyarrow]\",\n",
    "                        # **{\n",
    "                        #     k: \"float32[pyarrow]\"\n",
    "                        #     for k in list(filled_scalars) + list(recon_scalars) + list(rescaled_scalars)\n",
    "                        # },\n",
    "                    )\n",
    "                )\n",
    "                df.append(_df)\n",
    "                if i % 35 == 0:\n",
    "                    pd.concat(df, ignore_index=True).to_parquet(\n",
    "                        data_folder\n",
    "                        / f\"{experiment}_syllable_df_v{df_version:02d}.parquet\"\n",
    "                    )\n",
    "            except ValueError as e:\n",
    "                print(\"failure\", uuid, e)\n",
    "                failed_sessions.append((uuid, path))\n",
    "        df = pd.concat(df, ignore_index=True)\n",
    "        df.to_parquet(\n",
    "            data_folder / f\"{experiment}_syllable_df_v{df_version:02d}.parquet\"\n",
    "        )\n",
    "        print(experiment, \"length\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3662ac-3e29-419f-b753-e49b93358866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56049a88-f07f-4d21-aadb-e5109e7548e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009e6f2-6d08-4956-adf3-41823ee030eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ontogeny",
   "language": "python",
   "name": "aging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "008d07b5dfaa4eceab69dbfd3a70f991": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ae8cccaed3b9418cb17c2e6dbe0e7d28",
       "style": "IPY_MODEL_4b268723d62c42f68331e08315720ac5",
       "value": " 4058/? [06:09&lt;00:00, 12.28it/s]"
      }
     },
     "06ff4708750f4330862d5636d839114c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3aac5308c2d64591a410d9ad9c813a35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e832fee885884621913e1a62639b0d72",
        "IPY_MODEL_e4f9a943443e45a6857d6b656f6ed1db",
        "IPY_MODEL_008d07b5dfaa4eceab69dbfd3a70f991"
       ],
       "layout": "IPY_MODEL_43b8c7b77329480ca5ce64fb3b9de777"
      }
     },
     "43b8c7b77329480ca5ce64fb3b9de777": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b268723d62c42f68331e08315720ac5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "77dbd1dd79654c5f920810868554d7bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "841e878bcb144ab6b9c02a1eeb7b20f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ae8cccaed3b9418cb17c2e6dbe0e7d28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b80a20972fc54b5da7b3d0ea5dbe6153": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "e4f9a943443e45a6857d6b656f6ed1db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b80a20972fc54b5da7b3d0ea5dbe6153",
       "max": 1,
       "style": "IPY_MODEL_841e878bcb144ab6b9c02a1eeb7b20f8",
       "value": 1
      }
     },
     "e832fee885884621913e1a62639b0d72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_77dbd1dd79654c5f920810868554d7bf",
       "style": "IPY_MODEL_06ff4708750f4330862d5636d839114c"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
