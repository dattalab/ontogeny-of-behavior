{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to train ARHMM\n",
    "\n",
    "- find optimal kappa\n",
    "- use kappa to fit full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=.5\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=.5\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import h5py\n",
    "import joblib\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from toolz import valmap, valfilter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax_moseq.models import arhmm\n",
    "from jax_moseq.utils import batch, convert_data_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def whiten_all(data_dict, center=True):\n",
    "    \"\"\"\n",
    "    Whiten the PC Scores (with Cholesky decomposition) using all the data to compute the covariance matrix.\n",
    "\n",
    "    Args:\n",
    "    data_dict (OrderedDict): Training dataset\n",
    "    center (bool): Indicates whether to center data by subtracting the mean PC score.\n",
    "\n",
    "    Returns:\n",
    "    data_dict (OrderedDict): Whitened training data dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    non_nan = lambda x: x[~np.isnan(np.reshape(x, (x.shape[0], -1))).any(1)]\n",
    "    meancov = lambda x: (x.mean(0), np.cov(x, rowvar=False, bias=1))\n",
    "    contig = partial(np.require, dtype=np.float64, requirements='C')\n",
    "\n",
    "    mu, Sigma = meancov(np.concatenate(list(map(non_nan, data_dict.values()))))\n",
    "    L = np.linalg.cholesky(Sigma)\n",
    "\n",
    "    offset = 0. if center else mu\n",
    "    apply_whitening = lambda x:  np.linalg.solve(L, (x-mu).T).T + offset\n",
    "\n",
    "    return OrderedDict((k, contig(apply_whitening(v))) for k, v in data_dict.items())\n",
    "\n",
    "\n",
    "def concatenate_stateseqs(stateseqs, mask=None):\n",
    "    \"\"\"\n",
    "    Concatenate state sequences, optionally applying a mask.\n",
    "    Parameters\n",
    "    ----------\n",
    "    stateseqs: dict or ndarray, shape (..., t)\n",
    "        Dictionary mapping names to 1d arrays, or a single\n",
    "        multi-dimensional array representing a batch of state sequences\n",
    "        where the last dim indexes time\n",
    "    mask: ndarray, shape (..., >=t), default=None\n",
    "        Binary indicator for which elements of ``stateseqs`` are valid,\n",
    "        e.g. when state sequences of different lengths have been padded.\n",
    "        If ``mask`` contains more time-points than ``stateseqs``, the\n",
    "        initial extra time-points will be ignored.\n",
    "    Returns\n",
    "    -------\n",
    "    stateseqs_flat: ndarray\n",
    "        1d array containing all state sequences \n",
    "    \"\"\"\n",
    "    if isinstance(stateseqs, dict):\n",
    "        stateseq_flat = np.hstack(list(stateseqs.values()))\n",
    "    elif mask is not None:\n",
    "        stateseq_flat = stateseqs[mask[:, -stateseqs.shape[1]:] > 0]\n",
    "    else:\n",
    "        stateseq_flat = stateseqs.flatten()\n",
    "    return stateseq_flat\n",
    "\n",
    "\n",
    "def get_durations(stateseqs, mask=None):\n",
    "    \"\"\"\n",
    "    Get durations for a batch of state sequences. For a more detailed \n",
    "    description of the function parameters, see \n",
    "    :py:func:`keypoint_moseq.util.concatenate_stateseqs`\n",
    "    Parameters\n",
    "    ----------\n",
    "    stateseqs: dict or ndarray of shape (..., t)\n",
    "    mask: ndarray of shape (..., >=t), default=None\n",
    "    Returns\n",
    "    -------\n",
    "    durations: 1d array\n",
    "        The duration of each each state (across all state sequences)\n",
    "    Examples\n",
    "    --------\n",
    "    >>> stateseqs = {\n",
    "        'name1': np.array([1, 1, 2, 2, 2, 3]),\n",
    "        'name2': np.array([0, 0, 0, 1])\n",
    "    }\n",
    "    >>> get_durations(stateseqs)\n",
    "    array([2, 3, 1, 3, 1])\n",
    "    \"\"\"\n",
    "    stateseq_flat = concatenate_stateseqs(stateseqs, mask=mask).astype(int)\n",
    "    stateseq_padded = np.hstack([[-1], stateseq_flat, [-1]])\n",
    "    changepoints = np.diff(stateseq_padded).nonzero()[0]\n",
    "    return changepoints[1:]-changepoints[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = Path('/n/groups/datta/win/longtogeny/data/ontogeny/version_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_path = folder / '_pca/pca_scores.h5'\n",
    "\n",
    "with h5py.File(pca_path, 'r') as h5f:\n",
    "    pc_data = {k: h5f['scores'][k][:, :10] for k in h5f['scores']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pc_data = whiten_all(pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nan_threshold = 300  # frames\n",
    "pc_data = valfilter(lambda v: np.isnan(v).any(1).sum() < nan_threshold, pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2752092"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_frames = sum(map(len, pc_data.values()))\n",
    "total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_frames = 1.5e6\n",
    "frames_per_session = int(max_frames // len(pc_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data = valmap(lambda v: v[:frames_per_session], pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_states = 100\n",
    "nlags = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"x\"], data[\"mask\"], lbls = batch(pc_data)\n",
    "\n",
    "non_nans = ~jnp.isnan(data['x']).any(-1)\n",
    "mask = [jnp.roll(non_nans, shift) for shift in range(nlags + 1)]\n",
    "mask = jnp.all(jnp.array(mask), axis=0)\n",
    "\n",
    "data['mask'] = jnp.where(mask, data['mask'], 0)\n",
    "del mask\n",
    "del non_nans\n",
    "\n",
    "data['x'] = jnp.where(jnp.isnan(data['x']), 0, data['x'])\n",
    "data = convert_data_precision(data)\n",
    "data['mask'] = data['mask'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kappas = np.logspace(5, 8, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = obs_dim = data['x'].shape[-1]\n",
    "ar_hypparams = {\n",
    "    'S_0_scale': .01,\n",
    "    'K_0_scale': 10,\n",
    "    'num_states': num_states,\n",
    "    'nlags': nlags,\n",
    "    'latent_dim': latent_dim\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a900118a7d364fe5a7eda4c225aa3fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "kappa scan:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a32c27f43b4d5d883bec10464c0119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e656d7efef73458dbd09b4c43c863fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343ec71883dc4fec8348cd2ea35f515e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95054d9e0a1e493db0bd46e72c460662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2034e1d0ff141b797b2cb983f510433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46857bb08fe4e419900c9f70c28a7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14ecd75536e4f8d8c1feabf1bb8ebd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b6ebdb680c489b8742a742d75036d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f93f4769b354c438a132fe0a5c7fdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_iters = 35\n",
    "\n",
    "durations = {}\n",
    "agg_durations = {}\n",
    "for k in tqdm(kappas, desc='kappa scan'):\n",
    "    ll_keys = ['z', 'x']\n",
    "    ll_history = {key: [] for key in ll_keys}\n",
    "\n",
    "    trans_hypparams = {\n",
    "        'gamma': 1e3,\n",
    "        'alpha': 5.7,\n",
    "        'kappa': k,\n",
    "        'num_states': num_states\n",
    "    }\n",
    "\n",
    "    model = arhmm.init_model(\n",
    "        data,\n",
    "        ar_hypparams=ar_hypparams,\n",
    "        trans_hypparams=trans_hypparams,\n",
    "        robust=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    pbar = tqdm(range(num_iters))\n",
    "\n",
    "    _durs = []\n",
    "\n",
    "    for i in pbar:\n",
    "        # Perform Gibbs resampling\n",
    "        model = arhmm.resample_model(data, **model)\n",
    "\n",
    "        durs = get_durations(model['states']['z'], data['mask'])\n",
    "\n",
    "        # Compute the likelihood of the data and\n",
    "        # resampled states given the resampled params\n",
    "        ll = arhmm.model_likelihood(data, **model)\n",
    "        for key in ll_keys:\n",
    "            ll_history[key].append(ll[key].item())\n",
    "        pbar.set_description(f\"LL: {ll['x']:0.2e} -- Dur {np.mean(durs) / 30:0.2f}s {np.median(durs) / 30:0.2f}s\")\n",
    "        _durs.append(np.mean(durs))\n",
    "    durations[k] = (np.mean(durs) / 30, np.median(durs) / 30)\n",
    "    agg_durations[k] = _durs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_duration = valmap(lambda v: np.abs(v[0] - 0.6), durations)\n",
    "best_kappa = min(best_duration, key=best_duration.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100000.0: 0.33734039905930513,\n",
       " 237137.37056616554: 0.28311387930451254,\n",
       " 562341.3251903491: 0.22507948181110965,\n",
       " 1333521.432163324: 0.1702566396293333,\n",
       " 3162277.6601683795: 0.1134912133782564,\n",
       " 7498942.093324558: 49960.933333333334,\n",
       " 17782794.100389227: 0.009340395179659344,\n",
       " 42169650.342858225: 0.03690700797171653,\n",
       " 100000000.0: 0.08857373871018126}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17782794.100389227"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf79c051b7046778fd004b4e3bf6caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_iters = 1000\n",
    "ll_keys = ['z', 'x']\n",
    "ll_history = {key: [] for key in ll_keys}\n",
    "\n",
    "trans_hypparams = {\n",
    "    'gamma': 1e3,\n",
    "    'alpha': 5.7,\n",
    "    'kappa': best_kappa,\n",
    "    'num_states': num_states\n",
    "}\n",
    "\n",
    "model = arhmm.init_model(\n",
    "    data,\n",
    "    ar_hypparams=ar_hypparams,\n",
    "    trans_hypparams=trans_hypparams,\n",
    "    robust=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "pbar = tqdm(range(num_iters))\n",
    "\n",
    "for i in pbar:\n",
    "    # Perform Gibbs resampling\n",
    "    model = arhmm.resample_model(data, **model)\n",
    "    durs = get_durations(model['states']['z'], data['mask'])\n",
    "\n",
    "    # Compute the likelihood of the data and\n",
    "    # resampled states given the resampled params\n",
    "    ll = arhmm.model_likelihood(data, **model)\n",
    "    for key in ll_keys:\n",
    "        ll_history[key].append(ll[key].item())\n",
    "    pbar.set_description(f\"LL: {ll['x']:0.2e} -- Dur {np.mean(durs) / 30:0.2f}s {np.median(durs) / 30:0.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/n/groups/datta/win/longtogeny/data/ontogeny/version_02/model_params.p']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, folder / 'model_params.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-moseq",
   "language": "python",
   "name": "jax-moseq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00c63c8e2a4e465b9776ab5686d6f5b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "12a05b4459614d64b1fd4570629ffbdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "17a392e262c240ad8583d834485d6991": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2b2cd876e4b048caa3d2666b70c6eee0",
       "style": "IPY_MODEL_c813882c724847568ec5035fdf98d2d5",
       "value": " 1000/1000 [1:29:29&lt;00:00,  5.35s/it]"
      }
     },
     "1b65c46abaa548cf90f50a43934184ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "24f24f4beccd4b3b8cd4bfb2917c80ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2b2cd876e4b048caa3d2666b70c6eee0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b6b69de2e724bfd9d6769cbbb17e4b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_756cfaf401fe493f97a22336f7da36a2",
       "style": "IPY_MODEL_12a05b4459614d64b1fd4570629ffbdf",
       "value": "LL: -1.26e+07 -- Dur 0.55s 0.40s: 100%"
      }
     },
     "756cfaf401fe493f97a22336f7da36a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9f7f9760fc304cfe94d55d4d8c11075f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_00c63c8e2a4e465b9776ab5686d6f5b4",
       "max": 1000,
       "style": "IPY_MODEL_24f24f4beccd4b3b8cd4bfb2917c80ed",
       "value": 1000
      }
     },
     "c813882c724847568ec5035fdf98d2d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fcf79c051b7046778fd004b4e3bf6caa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4b6b69de2e724bfd9d6769cbbb17e4b9",
        "IPY_MODEL_9f7f9760fc304cfe94d55d4d8c11075f",
        "IPY_MODEL_17a392e262c240ad8583d834485d6991"
       ],
       "layout": "IPY_MODEL_1b65c46abaa548cf90f50a43934184ad"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
