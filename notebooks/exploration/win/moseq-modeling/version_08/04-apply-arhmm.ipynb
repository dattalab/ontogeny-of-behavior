{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3c85e-ded3-48b0-adca-4e7901a9a1f9",
   "metadata": {},
   "source": [
    "# Apply AR-HMM to rest of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9656084-9071-4659-8692-b6d5b913473b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wg41/miniconda3/envs/jax-moseq-og/lib/python3.10/site-packages/fastprogress/fastprogress.py:107: UserWarning: Couldn't import ipywidgets properly, progress bar will use console behavior\n",
      "  warn(\"Couldn't import ipywidgets properly, progress bar will use console behavior\")\n"
     ]
    }
   ],
   "source": [
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import h5py\n",
    "import joblib\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from toolz import partial, valmap, partition_all\n",
    "from jax_moseq.utils import batch, convert_data_precision, unbatch\n",
    "from jax_moseq.models.arhmm.gibbs import resample_discrete_stateseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4837dd-8a78-4c5c-9290-c7d656cc7017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = 8\n",
    "folder = Path(f'/n/groups/datta/win/longtogeny/data/ontogeny/version_{version:02d}')\n",
    "checkpoint_folder = Path(f\"/n/scratch3/users/w/wg41/moseq-model-checkpoints/version_{version:02d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432df40-cf87-456f-9ef3-ca8626553c7d",
   "metadata": {},
   "source": [
    "## Load training PCs, compute whitening parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37cda6c1-28fc-44c5-a758-8951ab1464f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_whitening(data, L, mu):\n",
    "    return np.linalg.solve(L, (data - mu).T).T\n",
    "\n",
    "\n",
    "def get_whitening_params(data_dict):\n",
    "    non_nan = lambda x: x[~np.isnan(np.reshape(x, (x.shape[0], -1))).any(1)]\n",
    "    meancov = lambda x: (x.mean(0), np.cov(x, rowvar=False, bias=1))\n",
    "    contig = partial(np.require, dtype=np.float64, requirements=\"C\")\n",
    "\n",
    "    mu, Sigma = meancov(np.concatenate(list(map(non_nan, data_dict.values()))))\n",
    "    L = np.linalg.cholesky(Sigma)\n",
    "\n",
    "    return mu, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338135a9-7b81-4d35-bafc-f967ae0c4a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_path = folder / '_pca/pca_scores.h5'\n",
    "\n",
    "with h5py.File(pca_path, 'r') as h5f:\n",
    "    pc_data = {k: h5f['scores'][k][:, :10] for k in h5f['scores']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a346397-ce02-4ef3-ad0f-492f60a9f1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu, L = get_whitening_params(pc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65cd514-5fa3-4966-bf84-6e82f9075008",
   "metadata": {},
   "source": [
    "## Load new data in batches, apply whitening and MoSeq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482ae882-767b-43fc-9321-85c9ca952b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (folder / \"model_params.p\").exists():\n",
    "    model = joblib.load(folder / 'model_params.p')\n",
    "else:\n",
    "    model = joblib.load(sorted(checkpoint_folder.glob(\"model_params*.p\"))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51822990-c51d-4e46-b186-d87b2c6250b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pcs_path = folder / 'all_data_pca/pca_scores.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a2567c-db76-4722-a835-c8a861775d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seed', 'states', 'params', 'hypparams']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d91c7ed-1498-4ed9-be5a-9dac86e48467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca38be8f0ff4fbfb6d8bad0cb4865ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 80\n",
    "\n",
    "syllables_file = all_pcs_path.with_name(\"syllables.h5\")\n",
    "# if the syllables file already exists, don't replace already computed data\n",
    "mode = \"a\" if syllables_file.exists() else \"w\"\n",
    "try:\n",
    "    h5f = h5py.File(syllables_file, 'r')\n",
    "    h5f.close()\n",
    "except OSError:\n",
    "    mode = \"w\"\n",
    "\n",
    "with h5py.File(all_pcs_path, \"r\") as h5f, h5py.File(syllables_file, mode) as out_h5:\n",
    "    if mode == \"w\":\n",
    "        seq = partition_all(batch_size, h5f[\"scores\"])\n",
    "    else:\n",
    "        seq = partition_all(batch_size, filter(lambda u: u not in out_h5.keys(), h5f[\"scores\"]))\n",
    "    for uuids in tqdm(list(seq)):\n",
    "        pc_data = {uuid: h5f[\"scores\"][uuid][:, :10] for uuid in uuids}\n",
    "        pc_data = valmap(partial(apply_whitening, L=L, mu=mu), pc_data)\n",
    "\n",
    "        data = {}\n",
    "        data[\"x\"], data[\"mask\"], (_keys, _bounds) = batch(pc_data)\n",
    "        data[\"mask\"] = jnp.where(jnp.isnan(data[\"x\"]).any(-1), 0, data[\"mask\"])\n",
    "        data[\"x\"] = jnp.where(jnp.isnan(data[\"x\"]), 0, data[\"x\"])\n",
    "        data = convert_data_precision(data)\n",
    "        data[\"mask\"] = data[\"mask\"].astype(\"int\")\n",
    "\n",
    "        z = resample_discrete_stateseqs(\n",
    "            **data, **model, **model[\"params\"], **model[\"hypparams\"], robust=True\n",
    "        )\n",
    "\n",
    "        z = unbatch(z, _keys, _bounds)\n",
    "        for k, v in z.items():\n",
    "            out_h5.create_dataset(k, data=v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9baef-29b2-48d8-8997-b9e8077080c7",
   "metadata": {},
   "source": [
    "## Compute AR likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e0857a-f9e7-4501-a886-dab6345e5a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "from functools import partial\n",
    "from jax_moseq.utils.autoregression import robust_ar_log_likelihood, get_nlags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69326240-e49e-4f03-8e97-b5eeb0c94e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_likelihood(x, mask, Ab, Q, **kwargs):\n",
    "    nlags = get_nlags(Ab)\n",
    "    log_likelihoods = jax.lax.map(\n",
    "        partial(robust_ar_log_likelihood, x),\n",
    "        (\n",
    "            Ab,\n",
    "            Q,\n",
    "            kwargs[\"nu\"],\n",
    "            jnp.tile(mask[None, ..., nlags:], (len(Ab), *(1,) * len(mask.shape))),\n",
    "        ),\n",
    "    )\n",
    "    return log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e86e84-0369-438f-9dc8-16d002fd8fff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c5e4a113094f9985f63173a253e59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 80\n",
    "\n",
    "syllables_file = all_pcs_path.with_name(\"ar_log_likelihoods.h5\")\n",
    "# if the syllables file already exists, don't replace already computed data\n",
    "mode = \"a\" if syllables_file.exists() else \"w\"\n",
    "try:\n",
    "    h5f = h5py.File(syllables_file, 'r')\n",
    "    h5f.close()\n",
    "except OSError:\n",
    "    mode = \"w\"\n",
    "\n",
    "with h5py.File(all_pcs_path, \"r\") as h5f, h5py.File(syllables_file, mode) as out_h5:\n",
    "    if mode == \"w\":\n",
    "        seq = partition_all(batch_size, h5f[\"scores\"])\n",
    "    else:\n",
    "        seq = partition_all(batch_size, filter(lambda u: u not in out_h5.keys(), h5f[\"scores\"]))\n",
    "    for uuids in tqdm(list(seq)):\n",
    "        pc_data = {uuid: h5f[\"scores\"][uuid][:, :10] for uuid in uuids}\n",
    "        pc_data = valmap(partial(apply_whitening, L=L, mu=mu), pc_data)\n",
    "\n",
    "        data = {}\n",
    "        data[\"x\"], data[\"mask\"], lbls = batch(pc_data)\n",
    "        data['mask'] = jnp.where(jnp.isnan(data['x']).any(-1), 0, data['mask'])\n",
    "        data['x'] = jnp.where(jnp.isnan(data['x']), 0, data['x'])\n",
    "        data = convert_data_precision(data)\n",
    "        data['mask'] = data['mask'].astype('int')\n",
    "\n",
    "        likes = compute_likelihood(**data, **model, **model['params'], **model['hypparams'])\n",
    "        likes = jnp.moveaxis(likes, 0, -1)\n",
    "        likes = unbatch(likes, lbls)\n",
    "\n",
    "        for k, v in likes.items():\n",
    "            out_h5.create_dataset(k, data=v.astype('float32'), compression='lzf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47234b10-a522-4536-a89b-6272beb1bdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-moseq-og",
   "language": "python",
   "name": "jax-moseq-og"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1a2918546f1c43afaab02988a6578f21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4e8572eaeb2648a18187952830c41155",
       "style": "IPY_MODEL_f9071d1ea7a24e44953828598b00d8da",
       "value": " 4/4 [17:00&lt;00:00, 231.31s/it]"
      }
     },
     "31fb97155e2843a2be7791476eca7ec1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4a8c543481f1457db7084686e8ed2cdf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4e8572eaeb2648a18187952830c41155": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6ca38be8f0ff4fbfb6d8bad0cb4865ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8ac70d6df6594a8e91e2d8a2bf4760dc",
        "IPY_MODEL_9d1739ef15454b92a59fa4fba9bd2382",
        "IPY_MODEL_1a2918546f1c43afaab02988a6578f21"
       ],
       "layout": "IPY_MODEL_4a8c543481f1457db7084686e8ed2cdf"
      }
     },
     "8ac70d6df6594a8e91e2d8a2bf4760dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_959ee76c7e2c41468ebb488afb3fda83",
       "style": "IPY_MODEL_f83494c9209740ec93e14f614aa06935",
       "value": "100%"
      }
     },
     "959ee76c7e2c41468ebb488afb3fda83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9d1739ef15454b92a59fa4fba9bd2382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a794ef94136441e88ebce7bc7e219ac1",
       "max": 4,
       "style": "IPY_MODEL_31fb97155e2843a2be7791476eca7ec1",
       "value": 4
      }
     },
     "a794ef94136441e88ebce7bc7e219ac1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f83494c9209740ec93e14f614aa06935": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f9071d1ea7a24e44953828598b00d8da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
