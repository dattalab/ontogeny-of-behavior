{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to train ARHMM\n",
    "\n",
    "- find optimal kappa\n",
    "- use kappa to fit full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wg41/miniconda3/envs/jax-moseq-og/lib/python3.10/site-packages/fastprogress/fastprogress.py:107: UserWarning: Couldn't import ipywidgets properly, progress bar will use console behavior\n",
      "  warn(\"Couldn't import ipywidgets properly, progress bar will use console behavior\")\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=.9\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "from jax_moseq.utils import set_mixed_map_iters, set_mixed_map_gpus\n",
    "\n",
    "import h5py\n",
    "import joblib\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from toolz import valmap, valfilter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax_moseq.models import arhmm\n",
    "from jax_moseq.utils import batch, convert_data_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def whiten_all(data_dict, center=True):\n",
    "    \"\"\"\n",
    "    Whiten the PC Scores (with Cholesky decomposition) using all the data to compute the covariance matrix.\n",
    "\n",
    "    Args:\n",
    "    data_dict (OrderedDict): Training dataset\n",
    "    center (bool): Indicates whether to center data by subtracting the mean PC score.\n",
    "\n",
    "    Returns:\n",
    "    data_dict (OrderedDict): Whitened training data dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    non_nan = lambda x: x[~np.isnan(np.reshape(x, (x.shape[0], -1))).any(1)]\n",
    "    meancov = lambda x: (x.mean(0), np.cov(x, rowvar=False, bias=1))\n",
    "    contig = partial(np.require, dtype=np.float64, requirements='C')\n",
    "\n",
    "    mu, Sigma = meancov(np.concatenate(list(map(non_nan, data_dict.values()))))\n",
    "    L = np.linalg.cholesky(Sigma)\n",
    "\n",
    "    offset = 0. if center else mu\n",
    "    apply_whitening = lambda x:  np.linalg.solve(L, (x-mu).T).T + offset\n",
    "\n",
    "    return OrderedDict((k, contig(apply_whitening(v))) for k, v in data_dict.items())\n",
    "\n",
    "\n",
    "def concatenate_stateseqs(stateseqs, mask=None):\n",
    "    \"\"\"\n",
    "    Concatenate state sequences, optionally applying a mask.\n",
    "    Parameters\n",
    "    ----------\n",
    "    stateseqs: dict or ndarray, shape (..., t)\n",
    "        Dictionary mapping names to 1d arrays, or a single\n",
    "        multi-dimensional array representing a batch of state sequences\n",
    "        where the last dim indexes time\n",
    "    mask: ndarray, shape (..., >=t), default=None\n",
    "        Binary indicator for which elements of ``stateseqs`` are valid,\n",
    "        e.g. when state sequences of different lengths have been padded.\n",
    "        If ``mask`` contains more time-points than ``stateseqs``, the\n",
    "        initial extra time-points will be ignored.\n",
    "    Returns\n",
    "    -------\n",
    "    stateseqs_flat: ndarray\n",
    "        1d array containing all state sequences \n",
    "    \"\"\"\n",
    "    if isinstance(stateseqs, dict):\n",
    "        stateseq_flat = np.hstack(list(stateseqs.values()))\n",
    "    elif mask is not None:\n",
    "        stateseq_flat = stateseqs[mask[:, -stateseqs.shape[1]:] > 0]\n",
    "    else:\n",
    "        stateseq_flat = stateseqs.flatten()\n",
    "    return stateseq_flat\n",
    "\n",
    "\n",
    "def get_durations(stateseqs, mask=None):\n",
    "    \"\"\"\n",
    "    Get durations for a batch of state sequences. For a more detailed \n",
    "    description of the function parameters, see \n",
    "    :py:func:`keypoint_moseq.util.concatenate_stateseqs`\n",
    "    Parameters\n",
    "    ----------\n",
    "    stateseqs: dict or ndarray of shape (..., t)\n",
    "    mask: ndarray of shape (..., >=t), default=None\n",
    "    Returns\n",
    "    -------\n",
    "    durations: 1d array\n",
    "        The duration of each each state (across all state sequences)\n",
    "    Examples\n",
    "    --------\n",
    "    >>> stateseqs = {\n",
    "        'name1': np.array([1, 1, 2, 2, 2, 3]),\n",
    "        'name2': np.array([0, 0, 0, 1])\n",
    "    }\n",
    "    >>> get_durations(stateseqs)\n",
    "    array([2, 3, 1, 3, 1])\n",
    "    \"\"\"\n",
    "    stateseq_flat = concatenate_stateseqs(stateseqs, mask=mask).astype(int)\n",
    "    stateseq_padded = np.hstack([[-1], stateseq_flat, [-1]])\n",
    "    changepoints = np.diff(stateseq_padded).nonzero()[0]\n",
    "    return changepoints[1:]-changepoints[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = 9\n",
    "folder = Path(f'/n/groups/datta/win/longtogeny/data/ontogeny/version_{version:02d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mixed_map_gpus(2)\n",
    "set_mixed_map_iters(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_path = folder / '_pca/pca_scores.h5'\n",
    "\n",
    "with h5py.File(pca_path, 'r') as h5f:\n",
    "    pc_data = {k: h5f['scores'][k][:, :10] for k in h5f['scores']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pc_data = whiten_all(pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nan_threshold = 300  # frames\n",
    "pc_data = valfilter(lambda v: np.isnan(v).any(1).sum() < nan_threshold, pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_data = {k: v for i, (k, v) in enumerate(pc_data.items()) if i < 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24806390"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_frames = sum(map(len, pc_data.values()))\n",
    "total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_frames = 24e7\n",
    "frames_per_session = int(max_frames // len(pc_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_per_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grab the middle of the dataset\n",
    "def slice_data(v):\n",
    "    diff = len(v) - frames_per_session\n",
    "    return v[diff // 2:frames_per_session + diff // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data = valmap(slice_data, pc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_states = 100\n",
    "nlags = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    data[\"x\"], data[\"mask\"], lbls = batch(pc_data)\n",
    "\n",
    "non_nans = ~jnp.isnan(data['x']).any(-1)\n",
    "mask = [jnp.roll(non_nans, shift) for shift in range(nlags + 1)]\n",
    "mask = jnp.all(jnp.array(mask), axis=0)\n",
    "\n",
    "data['mask'] = jnp.where(mask, data['mask'], 0)\n",
    "del mask\n",
    "del non_nans\n",
    "\n",
    "data['x'] = jnp.where(jnp.isnan(data['x']), 0, data['x'])\n",
    "data = convert_data_precision(data, x64=True)\n",
    "data['mask'] = data['mask'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kappas = np.logspace(8, 9, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = obs_dim = data['x'].shape[-1]\n",
    "ar_hypparams = {\n",
    "    'S_0_scale': .01,\n",
    "    'K_0_scale': 10,\n",
    "    'num_states': num_states,\n",
    "    'nlags': nlags,\n",
    "    'latent_dim': latent_dim\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_kappa(kappas, num_iters=10):\n",
    "    durations = {}\n",
    "    # agg_durations = {}\n",
    "    for k in tqdm(kappas, desc=\"kappa scan\"):\n",
    "        # ll_keys = ['z', 'x']\n",
    "        # ll_history = {key: [] for key in ll_keys}\n",
    "\n",
    "        trans_hypparams = {\n",
    "            \"gamma\": 1e3,\n",
    "            \"alpha\": 5.7,\n",
    "            \"kappa\": k,\n",
    "            \"num_states\": num_states,\n",
    "        }\n",
    "\n",
    "        model = arhmm.init_model(\n",
    "            data,\n",
    "            ar_hypparams=ar_hypparams,\n",
    "            trans_hypparams=trans_hypparams,\n",
    "            robust=False,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        pbar = tqdm(range(num_iters))\n",
    "\n",
    "        _durs = []\n",
    "\n",
    "        for i in pbar:\n",
    "            # Perform Gibbs resampling\n",
    "            model = arhmm.resample_model(data, **model, verbose=False)\n",
    "\n",
    "            durs = get_durations(model[\"states\"][\"z\"], data[\"mask\"])\n",
    "\n",
    "            # Compute the likelihood of the data and\n",
    "            # resampled states given the resampled params\n",
    "            # ll = arhmm.model_likelihood(data, **model)\n",
    "            # for key in ll_keys:\n",
    "            #     ll_history[key].append(ll[key].item())\n",
    "            # pbar.set_description(f\"LL: {ll['x']:0.2e} -- Dur {np.mean(durs) / 30:0.2f}s {np.median(durs) / 30:0.2f}s\")\n",
    "            pbar.set_description(\n",
    "                f\"Dur {np.mean(durs) / 30:0.2f}s {np.median(durs) / 30:0.2f}s\"\n",
    "            )\n",
    "            _durs.append(np.mean(durs))\n",
    "        durations[k] = (np.mean(durs) / 30, np.median(durs) / 30)\n",
    "        # agg_durations[k] = _durs\n",
    "    best_duration = valmap(lambda v: np.abs(v[0] - 0.6), durations)\n",
    "    best_kappa = min(best_duration, key=best_duration.get)\n",
    "    return best_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(f\"/n/scratch3/users/w/wg41/moseq-model-checkpoints/version_{version:02d}\")\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "checkpoints = sorted(checkpoint_path.glob(\"model_params*.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 1000\n",
    "start = 0 if len(checkpoints) == 0 else int(checkpoints[-1].stem.split('_')[-1]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b71b1f7f4146ad80e456eeed31fec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "kappa scan:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARHMM: Initializing hyperparameters\n",
      "ARHMM: Initializing parameters\n",
      "ARHMM: Initializing states\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 23:17:19.550994: W external/tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 11.59GiB (rounded to 12448480000)requested by op \n",
      "2023-11-20 23:17:19.551148: W external/tsl/tsl/framework/bfc_allocator.cc:497] *******______*******************************________________________________________________________\n",
      "2023-11-20 23:17:19.551684: E external/xla/xla/pjrt/pjrt_stream_executor_client.cc:2716] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 12448479912 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:  652.96MiB\n",
      "              constant allocation:   476.7KiB\n",
      "        maybe_live_out allocation:   59.36MiB\n",
      "     preallocated temp allocation:   11.59GiB\n",
      "                 total allocation:   12.29GiB\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 5.80GiB\n",
      "\t\tOperator: op_name=\"pmap(partial_fun)/jit(main)/jit(partial_fun)/vmap(jit(_sample))/mul\" source_file=\"/home/wg41/code/jax-moseq-og/jax_moseq/utils/distributions.py\" source_line=89\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[54028,144,100]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 5.80GiB\n",
      "\t\tOperator: op_name=\"pmap(partial_fun)/jit(main)/jit(partial_fun)/vmap(jit(_sample))/jit(hmm_posterior_sample)/jit(hmm_filter)/broadcast_in_dim[shape=(54028, 144, 100) broadcast_dimensions=()]\" source_file=\"/home/wg41/code/jax-moseq-og/jax_moseq/utils/distributions.py\" source_line=90\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[54028,144,100]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 593.60MiB\n",
      "\t\tOperator: op_name=\"pmap(partial_fun)/jit(main)/jit(partial_fun)/vmap(jit(_sample))/while[cond_nconsts=0 body_nconsts=3]\" source_file=\"/home/wg41/code/jax-moseq-og/jax_moseq/models/arhmm/gibbs.py\" source_line=58\n",
      "\t\tEntry Parameter Subshape: f64[144,54031,10]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 59.36MiB\n",
      "\t\tEntry Parameter Subshape: f64[144,54028]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 5:\n",
      "\t\tSize: 59.36MiB\n",
      "\t\tOperator: op_name=\"pmap(partial_fun)/jit(main)/jit(partial_fun)/vmap(jit(_sample))/jit(hmm_posterior_sample)/concatenate[dimension=1]\" source_file=\"/home/wg41/code/jax-moseq-og/jax_moseq/utils/distributions.py\" source_line=90\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: s64[144,54028]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 6:\n",
      "\t\tSize: 242.2KiB\n",
      "\t\tXLA Label: constant\n",
      "\t\tShape: f64[100,10,31]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 7:\n",
      "\t\tSize: 112.5KiB\n",
      "\t\tOperator: op_name=\"pmap(partial_fun)/jit(main)/jit(partial_fun)/vmap(jit(_sample))/jit(hmm_posterior_sample)/jit(hmm_filter)/broadcast_in_dim[shape=(144, 100) broadcast_dimensions=(1,)]\" source_file=\"/home/wg41/code/jax-moseq-og/jax_moseq/utils/distributions.py\" source_line=90\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f64[144,100]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 8:\n",
      "\t\tSize: 78.1KiB\n",
      "\t\tXLA Label: constant\n",
      "\t\tShape: f64[100,10,10]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 9:\n",
      "\t\tSize: 78.1KiB\n",
      "\t\tXLA Label: constant\n",
      "\t\tShape: f64[100,100]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 10:\n",
      "\t\tSize: 78.1KiB\n",
      "\t\tXLA Label: constant\n",
      "\t\tShape: f64[100,100]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 11:\n",
      "\t\tSize: 1.1KiB\n",
      "\t\tEntry Parameter Subshape: u32[144,2]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 12:\n",
      "\t\tSize: 40B\n",
      "\t\tXLA Label: tuple\n",
      "\t\tShape: (s64[], f64[144,100], f64[54028,144,100], s64[54028], f64[144,54028,100])\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 13:\n",
      "\t\tSize: 40B\n",
      "\t\tXLA Label: tuple\n",
      "\t\tShape: (s64[], s32[144], s32[144], f64[144,100], f64[144])\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 14:\n",
      "\t\tSize: 40B\n",
      "\t\tXLA Label: tuple\n",
      "\t\tShape: (s64[], s64[144], s64[54027,144], u32[54027,144,2], f64[54027,144,100])\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 15:\n",
      "\t\tSize: 40B\n",
      "\t\tXLA Label: tuple\n",
      "\t\tShape: (s64[], s32[144], s32[144], f64[144,100], f64[144])\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ll_keys = ['z', 'x']\n",
    "ll_history = {key: [] for key in ll_keys}\n",
    "\n",
    "\n",
    "if start == 0:\n",
    "    best_kappa = find_kappa(kappas, num_iters=10)\n",
    "    trans_hypparams = {\n",
    "        'gamma': 1e3,\n",
    "        'alpha': 5.7,\n",
    "        'kappa': best_kappa,\n",
    "        'num_states': num_states\n",
    "    }\n",
    "    model = arhmm.init_model(\n",
    "        data,\n",
    "        ar_hypparams=ar_hypparams,\n",
    "        trans_hypparams=trans_hypparams,\n",
    "        robust=False,\n",
    "        verbose=False\n",
    "    )\n",
    "else:\n",
    "    model = joblib.load(checkpoints[-1])\n",
    "\n",
    "pbar = tqdm(range(start, num_iters))\n",
    "\n",
    "for i in pbar:\n",
    "    # Perform Gibbs resampling\n",
    "    model = arhmm.resample_model(data, **model)\n",
    "    # durs = get_durations(model['states']['z'], data['mask'])\n",
    "\n",
    "    # Compute the likelihood of the data and\n",
    "    # resampled states given the resampled params\n",
    "    # ll = arhmm.model_likelihood(data, **model)\n",
    "    # for key in ll_keys:\n",
    "    #     ll_history[key].append(ll[key].item())\n",
    "    # pbar.set_description(f\"LL: {ll['x']:0.2e} -- Dur {np.mean(durs) / 30:0.2f}s {np.median(durs) / 30:0.2f}s\")\n",
    "    if i % 4 == 0:\n",
    "        joblib.dump(model, checkpoint_path / f\"model_params_{i:03d}.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(model, folder / 'model_params.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-moseq-og",
   "language": "python",
   "name": "jax-moseq-og"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0dd1228bd998448588bd70cf9a12ef09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1d105da8fc82471b87cc0eed70e22c69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_0dd1228bd998448588bd70cf9a12ef09",
       "max": 3,
       "style": "IPY_MODEL_90a777a68bfa455fa48444f67ab7cb51"
      }
     },
     "31b2b8e7fe154703a7c7502ae7e60feb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39b71b1f7f4146ad80e456eeed31fec1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_edf65351b07549038b60524da4627d7b",
        "IPY_MODEL_1d105da8fc82471b87cc0eed70e22c69",
        "IPY_MODEL_5506a181658647ef843becf7eb1700dc"
       ],
       "layout": "IPY_MODEL_31b2b8e7fe154703a7c7502ae7e60feb"
      }
     },
     "52b1047934b345a387a820ad80ee60b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5506a181658647ef843becf7eb1700dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d1cbc6fb85264afd84b99a9a4b63dd11",
       "style": "IPY_MODEL_52b1047934b345a387a820ad80ee60b0",
       "value": " 0/3 [00:00&lt;?, ?it/s]"
      }
     },
     "86c4ddcd9f2e400eb4c7f8bc1e4e74de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "90a777a68bfa455fa48444f67ab7cb51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d1cbc6fb85264afd84b99a9a4b63dd11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e398bf625574459db81abf386b452b12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "edf65351b07549038b60524da4627d7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_86c4ddcd9f2e400eb4c7f8bc1e4e74de",
       "style": "IPY_MODEL_e398bf625574459db81abf386b452b12",
       "value": "kappa scan:   0%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
