{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize morphological transformation vectors to map 12w old mice onto all other ages\n",
    "\n",
    "Run this notebook on a gpu for fast training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "from kornia.geometry.transform import scale\n",
    "from aging.plotting import figure, format_plots\n",
    "from aging.organization.paths import TrainingPaths\n",
    "from toolz import keyfilter, concatv, take, partition_all\n",
    "from aging.size_norm.data import make_grid, pad_vector\n",
    "from kornia.geometry.transform import warp_image_tps, get_tps_transform, resize, elastic_transform2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = TrainingPaths()\n",
    "training_paths.tps_fits.parent.mkdir(exist_ok=True, parents=True)\n",
    "poses = joblib.load(training_paths.tps_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(grid_size=6, batch_size=1, device=\"cpu\"):\n",
    "    # movement_vector = torch.zeros(batch_size, 2, grid_size - 2, grid_size - 2, requires_grad=True)\n",
    "    movement_vector = torch.zeros(\n",
    "        batch_size, 2, grid_size, grid_size, requires_grad=True, device=device\n",
    "    )\n",
    "    scale_tensor = torch.ones(batch_size, 2, dtype=torch.float, requires_grad=True, device=device)\n",
    "    height_mtx = torch.ones(batch_size, 1, 5, 8, requires_grad=True, device=device)\n",
    "    return {\n",
    "        \"movement_vector\": movement_vector,\n",
    "        \"scale_tensor\": scale_tensor,\n",
    "        \"height_mtx\": height_mtx,\n",
    "    }\n",
    "\n",
    "\n",
    "def fit(template, target, grid_size=6, num_iters=1000, lr=1e-2, **tqdm_kwargs):\n",
    "    batch_size = len(template)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    template = torch.tensor(template, dtype=torch.float, device=device).view(\n",
    "        batch_size, 1, *template.shape[-2:]\n",
    "    )\n",
    "    target = torch.tensor(target, dtype=torch.float, device=device).view(\n",
    "        batch_size, 1, *target.shape[-2:]\n",
    "    )\n",
    "\n",
    "    # grid = make_grid(grid_size, batch_size)\n",
    "    params = initialize_params(grid_size, batch_size, device=device)\n",
    "    optimizer = torch.optim.AdamW(params.values(), lr=lr, weight_decay=1e-3)\n",
    "\n",
    "    losses = []\n",
    "    for i in tqdm(range(num_iters), **tqdm_kwargs):\n",
    "        optimizer.zero_grad()\n",
    "        # TODO: try elastic transform instead\n",
    "        # padded_vector = torch.transpose(pad_vector(params[\"movement_vector\"]), 1, 3)\n",
    "        # kernel, affine = get_tps_transform(grid + padded_vector.reshape(batch_size, -1, 2), grid)\n",
    "        scaled_template = scale(template, params[\"scale_tensor\"])\n",
    "        elastic_intermediate = resize(params[\"movement_vector\"], target.shape[-2:])\n",
    "        transformed_template = elastic_transform2d(\n",
    "            scaled_template, elastic_intermediate, kernel_size=(53, 53), sigma=(5, 5)\n",
    "        )\n",
    "        # transformed_template = warp_image_tps(scaled_template, grid, kernel, affine)\n",
    "        height_intermediate = resize(params[\"height_mtx\"], target.shape[-2:])\n",
    "\n",
    "        out = height_intermediate * transformed_template\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return {\n",
    "        \"params\": {k: v.detach().squeeze().cpu().numpy() for k, v in params.items()},\n",
    "        \"losses\": losses,\n",
    "        \"optimized_template\": out.detach().squeeze().cpu().numpy().astype(\"uint8\"),\n",
    "        \"template\": template.detach().squeeze().cpu().numpy().astype(\"uint8\"),\n",
    "        \"target\": target.detach().squeeze().cpu().numpy().astype(\"uint8\"),\n",
    "        # \"grid\": grid.detach().squeeze().numpy(),\n",
    "        # \"transformed_grid\": (\n",
    "        #     grid + torch.transpose(pad_vector(params[\"movement_vector\"]), 1, 3).reshape(batch_size, -1, 2)\n",
    "        # )\n",
    "        # .detach()\n",
    "        # .squeeze()\n",
    "        # .numpy(),\n",
    "    }\n",
    "\n",
    "\n",
    "def flatten_dict_recursive(input_dict, top_key=None):\n",
    "    flattened_list = []\n",
    "\n",
    "    for key, value in input_dict.items():\n",
    "        if isinstance(value, dict):\n",
    "            # If the value is a dictionary, recursively call the function\n",
    "            flattened_list.extend(\n",
    "                flatten_dict_recursive(\n",
    "                    value, top_key=key if top_key is None else top_key\n",
    "                )\n",
    "            )\n",
    "        elif isinstance(value, list):\n",
    "            # If the value is a list, iterate over its elements and append to the result\n",
    "            for item in value:\n",
    "                flattened_list.append((top_key, key, item))\n",
    "        else:\n",
    "            # If the value is neither a dictionary nor a list, append to the result\n",
    "            flattened_list.append((top_key, key, value))\n",
    "\n",
    "    return flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "pose_list = flatten_dict_recursive(keyfilter(lambda k: k != 12, poses))\n",
    "# 8 new animals, and 8 old animals\n",
    "template_pose_list = list(poses[12].items())\n",
    "random.shuffle(template_pose_list)\n",
    "n_animals = 13\n",
    "full_list = list(product(pose_list, template_pose_list[:n_animals]))\n",
    "random.shuffle(full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49e88bdf781444a91b19e8c4fca55a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = defaultdict(dict)\n",
    "grid_size = 15\n",
    "batch_size = 20\n",
    "for i, grp in enumerate(partition_all(batch_size, tqdm(full_list))):\n",
    "    ages = [i[0][0] for i in grp]\n",
    "    paths = [i[0][1] for i in grp]\n",
    "    targets = np.array([i[0][2] for i in grp])\n",
    "    template_paths = [i[1][0] for i in grp]\n",
    "    templates = np.array([i[1][1] for i in grp])\n",
    "    out = fit(templates, targets, grid_size=grid_size, num_iters=150, lr=1e-2, disable=True)\n",
    "    for j in range(batch_size):\n",
    "        output[ages[j]][(paths[j], template_paths[j])] = {\n",
    "            'params': {\n",
    "                'movement_vector': out['params']['movement_vector'][j],\n",
    "                'scale_tensor': out['params']['scale_tensor'][j],\n",
    "                'height_mtx': out['params']['height_mtx'][j],\n",
    "            },\n",
    "            'losses': out['losses'],\n",
    "            'optimized_template': out['optimized_template'][j],\n",
    "            'template': out['template'][j],\n",
    "            'target': out['target'][j],\n",
    "            # 'grid': out['grid'][j],\n",
    "            # 'transformed_grid': out['transformed_grid'][j]\n",
    "        }\n",
    "    if (i + 1) % 100 == 0:\n",
    "        joblib.dump(output, training_paths.tps_fits, compress=3)\n",
    "joblib.dump(output, training_paths.tps_fits, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out['template'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out['optimized_template'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out['params']['movement_vector'][0, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out['params']['movement_vector'][0, 1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(out['losses'])\n",
    "print(out['losses'][-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ontogeny",
   "language": "python",
   "name": "aging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
